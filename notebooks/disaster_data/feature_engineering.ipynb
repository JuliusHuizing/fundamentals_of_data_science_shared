{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.disaster_data_utils import *\n",
    "import numpy as np\n",
    "df = build_dataframe()\n",
    "df = build_clean_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julius/Library/Caches/pypoetry/virtualenvs/fundamentals-project-Gbp0IE_5-py3.11/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each country, for each year, we want one feature vector containg good predictors for the content of the speech they give that year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dis No', 'Year', 'Seq', 'Glide', 'Disaster Group', 'Disaster Subgroup',\n",
       "       'Disaster Type', 'Disaster Subtype', 'Disaster Subsubtype',\n",
       "       'Event Name', 'Country', 'ISO', 'Region', 'Continent', 'Location',\n",
       "       'Origin', 'Associated Dis', 'Associated Dis2', 'OFDA Response',\n",
       "       'Appeal', 'Declaration', 'AID Contribution ('000 US$)', 'Dis Mag Value',\n",
       "       'Dis Mag Scale', 'Latitude', 'Longitude', 'Local Time', 'River Basin',\n",
       "       'Start Year', 'Start Month', 'Start Day', 'End Year', 'End Month',\n",
       "       'End Day', 'Total Deaths', 'No Injured', 'No Affected', 'No Homeless',\n",
       "       'Total Affected', 'Reconstruction Costs ('000 US$)',\n",
       "       'Reconstruction Costs, Adjusted ('000 US$)',\n",
       "       'Insured Damages ('000 US$)', 'Insured Damages, Adjusted ('000 US$)',\n",
       "       'Total Damages ('000 US$)', 'Total Damages, Adjusted ('000 US$)', 'CPI',\n",
       "       'Adm Level', 'Admin1 Code', 'Admin2 Code', 'Geo Locations',\n",
       "       'causes climate change sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_vector_v1(df, country, year) -> np.array:\n",
    "    '''\n",
    "    Returns a feature vector for the given country in the given year using the information present in the provided dataframe.\n",
    "\n",
    "            Parameters:\n",
    "                    df (pd.DataFrame): The dataframe containing the disaster data\n",
    "                    country (string): The country to build the feature vector for\n",
    "                    year (int): The year to build the feature vector for\n",
    "\n",
    "            Returns:\n",
    "                    vector (np.array): a feature vector for the given country in the given year\n",
    "    '''\n",
    "    row = df[(df['Country'] == country) & (df['Year'] == year)]\n",
    "    num_disasters = len(row)\n",
    "    num_deaths = row['Total Deaths'].sum()\n",
    "    num_deaths_per_disaster = num_deaths / num_disasters\n",
    "    num_deaths_at_biggest_disaster = row['Total Deaths'].max()\n",
    "    vector = np.array([num_disasters, num_deaths, num_deaths_per_disaster, num_deaths_at_biggest_disaster])\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.        , 322.        ,  53.66666667, 143.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_feature_vector_v1(df, 'Indonesia', 2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. From what year onwards are we going to use the data?\n",
    "  - I.e. from what year onwards is the data complete / accuracte?\n",
    "  - i.e. from what year onwards is climate change a theme that governments talk about?\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X{array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "def create_feature_matrix(df, years, feature_vector_builder = build_feature_vector_v1) -> np.array:\n",
    "    \"\"\"\n",
    "    Create a feature matrix for a given DataFrame and list of years.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame containing data for different countries and years.\n",
    "    - years (list): A list of years for which feature vectors should be created.\n",
    "    - feature_vector_builder (callable): A function used to build feature vectors for each country and year.\n",
    "                                         Default is build_feature_vector_v1.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: A 2D numpy array representing the feature matrix, where each row corresponds to a country-year pair.\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    from utils.disaster_data_utils import *\n",
    "    import numpy as np\n",
    "    df = build_dataframe()\n",
    "    df = build_clean_dataframe(df)\n",
    "    feature_matrix = create_feature_matrix(df, np.arange(2000, 2005))\n",
    "    ```\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for country in df['Country'].unique():\n",
    "        for year in years:\n",
    "            feature_vector = build_feature_vector_v1(df, country, year)\n",
    "            result.append(feature_vector)\n",
    "    return np.array(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pz/pqdfb44x6z56nqs5vr77b6rw0000gn/T/ipykernel_23360/898069540.py:16: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  num_deaths_per_disaster = num_deaths / num_disasters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(452, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_years = np.arange(2019, 2021)\n",
    "X_train = create_feature_matrix(df, train_years)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5 Steps to use the Scikit-learn Estimator API:\n",
    "\n",
    "# # 1. Select model and import it\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # 2. Select model hyperparameters\n",
    "# model = LinearRegression(fit_intercept=True) # select model hyperparameters\n",
    "\n",
    "# # 3. Arrange data in feature matrix (or vector if just 1 feature) and Target array\n",
    "# X = x[\"Log GDP per capita\"].values\n",
    "# Y = x[\"Healthy life expectancy at birth\"].values\n",
    "\n",
    "# # 4. Fit model to data, [:, np.newaxis] is used to increase a dimension of X making it a column vector,\n",
    "# # which is the expected input for fit function.\n",
    "# model.fit(X[:, np.newaxis], Y)\n",
    "\n",
    "# # 5. Apply model\n",
    "# # TODO: we could also fit do predictions on the original X data. But it is better practice to show model performance on unseen data as done below.\n",
    "# xfit = np.linspace(6, 12, 2) # these values (6 and 12) were chosen by inspecting, visually, the datapoints in the plot\n",
    "# xfit = np.linspace(min(X), max(X), 2) # suggestion of a more general alternative\n",
    "\n",
    "# yfit = model.predict(xfit[:, np.newaxis])\n",
    "\n",
    "# # Plot\n",
    "# plt.scatter(X, Y, c='black')\n",
    "# plt.plot(xfit, yfit, c='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundamentals-project-Gbp0IE_5-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
